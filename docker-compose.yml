version: '3.8'

services:
  # üöÄ Main FastAPI Application (without AI models)
  mefapex-app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mefapex-chatbox
    ports:
      - "${APP_PORT:-8000}:8000"
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - DEBUG=${DEBUG:-true}
      - DATABASE_URL=postgresql://mefapex:mefapex@postgres:5432/mefapex_chatbot
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=mefapex
      - POSTGRES_PASSWORD=mefapex
      - POSTGRES_DB=mefapex_chatbot
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - USE_OPENAI=${USE_OPENAI:-false}
      - USE_HUGGINGFACE=${USE_HUGGINGFACE:-true}
      - CORS_ORIGINS=${CORS_ORIGINS:-http://localhost:3000,http://localhost:8000,http://localhost:8001}
      - SECRET_KEY=${SECRET_KEY:-dev-secret-key}
      # ü§ñ AI Mikroservis Konfig√ºrasyonu
      - AI_SERVICE_ENABLED=${AI_SERVICE_ENABLED:-true}
      - AI_SERVICE_HOST=mefapex-ai
      - AI_SERVICE_PORT=8001
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./content:/app/content
    depends_on:
      - postgres
      - qdrant
      - redis
      - mefapex-ai
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - mefapex-network

  # ü§ñ AI Mikroservisi
  mefapex-ai:
    build:
      context: .
      dockerfile: services/ai_service/Dockerfile
    container_name: mefapex-ai-service
    ports:
      - "${AI_SERVICE_PORT:-8001}:8001"
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - DEBUG=${DEBUG:-true}
      - AI_MODELS_PATH=/app/models_cache
      - TORCH_HOME=/app/models_cache/torch
      - HF_HOME=/app/models_cache/huggingface
    volumes:
      - ./models_cache:/app/models_cache
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s  # AI modelleri y√ºklenmesi zaman alabilir
    networks:
      - mefapex-network
    deploy:
      resources:
        limits:
          memory: 4G  # AI modelleri i√ßin hafƒ±za sƒ±nƒ±rƒ±
        reservations:
          memory: 2G

  # üóÑÔ∏è PostgreSQL Database with Performance Optimizations
  postgres:
    image: postgres:15-alpine
    container_name: mefapex-postgres
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    environment:
      - POSTGRES_DB=mefapex_chatbot
      - POSTGRES_USER=mefapex
      - POSTGRES_PASSWORD=mefapex
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
      # Performance optimizations
      - POSTGRES_HOST_AUTH_METHOD=md5
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/01_init.sql:ro
      - ./database/optimizations.sql:/docker-entrypoint-initdb.d/02_optimizations.sql:ro
      - ./database/postgresql_optimized.conf:/etc/postgresql/postgresql.conf:ro
    command: >
      postgres 
      -c max_connections=200
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=4MB
      -c min_wal_size=1GB
      -c max_wal_size=4GB
      -c autovacuum_max_workers=3
      -c autovacuum_naptime=20s
      -c autovacuum_vacuum_threshold=50
      -c autovacuum_analyze_threshold=50
      -c autovacuum_vacuum_scale_factor=0.1
      -c autovacuum_analyze_scale_factor=0.05
      -c log_min_duration_statement=1000
      -c log_checkpoints=on
      -c log_connections=on
      -c log_disconnections=on
      -c log_lock_waits=on
      -c bgwriter_delay=200ms
      -c bgwriter_lru_maxpages=100
      -c bgwriter_lru_multiplier=2.0
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U mefapex -d mefapex_chatbot"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - mefapex-network

  # üóÑÔ∏è Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: mefapex-qdrant
    ports:
      - "${QDRANT_PORT:-6333}:6333"
      - "6334:6334"
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    volumes:
      - qdrant_data:/qdrant/storage
    restart: unless-stopped
    networks:
      - mefapex-network

  # üóÇÔ∏è Redis Cache
  redis:
    image: redis:7.2-alpine
    container_name: mefapex-redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - mefapex-network

  # üìä Nginx Reverse Proxy (Production only)
  nginx:
    image: nginx:alpine
    container_name: mefapex-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./static:/var/www/html/static:ro
    depends_on:
      - mefapex-app
    restart: unless-stopped
    networks:
      - mefapex-network
    profiles:
      - production

  # üìà Monitoring (Production only)
  monitoring:
    image: prom/prometheus:latest
    container_name: mefapex-monitoring
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    restart: unless-stopped
    networks:
      - mefapex-network
    profiles:
      - production

volumes:
  postgres_data:
    driver: local
  qdrant_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local

networks:
  mefapex-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
