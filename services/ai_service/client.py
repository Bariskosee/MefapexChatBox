"""
ğŸ¤– AI Mikroservisi Ä°stemcisi
==========================
Ana uygulama ile AI mikroservisi arasÄ±ndaki iletiÅŸimi saÄŸlar
"""
import logging
import asyncio
import aiohttp
import json
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import time

logger = logging.getLogger(__name__)

@dataclass
class AIServiceConfig:
    """AI servis yapÄ±landÄ±rmasÄ±"""
    host: str = "127.0.0.1"
    port: int = 8001
    timeout: int = 30
    retry_attempts: int = 3
    retry_delay: float = 1.0

class AIServiceError(Exception):
    """AI servis hatasÄ±"""
    pass

class AIServiceUnavailableError(AIServiceError):
    """AI servis eriÅŸilemez"""
    pass

class AIServiceClient:
    """
    AI Mikroservisi Ä°stemcisi
    =========================
    Ana uygulama ile AI mikroservisi arasÄ±ndaki tÃ¼m iletiÅŸimi yÃ¶netir
    """
    
    def __init__(self, config: AIServiceConfig = None):
        self.config = config or AIServiceConfig()
        self.base_url = f"http://{self.config.host}:{self.config.port}"
        self.session: Optional[aiohttp.ClientSession] = None
        self._service_available = False
        self._last_health_check = 0
        self._health_check_interval = 60  # 1 dakika
        
    async def __aenter__(self):
        """Async context manager giriÅŸ"""
        await self.start()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager Ã§Ä±kÄ±ÅŸ"""
        await self.close()
    
    async def start(self):
        """Ä°stemciyi baÅŸlat"""
        if self.session is None:
            timeout = aiohttp.ClientTimeout(total=self.config.timeout)
            self.session = aiohttp.ClientSession(timeout=timeout)
        
        # Servis saÄŸlÄ±k kontrolÃ¼
        await self._check_service_health()
    
    async def close(self):
        """Ä°stemciyi kapat"""
        if self.session:
            await self.session.close()
            self.session = None
    
    async def _check_service_health(self) -> bool:
        """AI servis saÄŸlÄ±k kontrolÃ¼"""
        try:
            current_time = time.time()
            
            # Cache'li saÄŸlÄ±k kontrolÃ¼
            if (current_time - self._last_health_check) < self._health_check_interval:
                return self._service_available
            
            if not self.session:
                await self.start()
            
            async with self.session.get(f"{self.base_url}/health") as response:
                if response.status == 200:
                    health_data = await response.json()
                    self._service_available = health_data.get("status") == "healthy"
                    self._last_health_check = current_time
                    
                    if self._service_available:
                        logger.debug("âœ… AI servis saÄŸlÄ±klÄ±")
                    else:
                        logger.warning("âš ï¸ AI servis saÄŸlÄ±ksÄ±z durumda")
                    
                    return self._service_available
                else:
                    self._service_available = False
                    logger.warning(f"âš ï¸ AI servis saÄŸlÄ±k kontrolÃ¼ baÅŸarÄ±sÄ±z: {response.status}")
                    return False
                    
        except Exception as e:
            self._service_available = False
            logger.error(f"âŒ AI servis saÄŸlÄ±k kontrolÃ¼ hatasÄ±: {e}")
            return False
    
    async def _make_request(self, method: str, endpoint: str, data: Dict = None) -> Dict:
        """HTTP isteÄŸi yap"""
        if not await self._check_service_health():
            raise AIServiceUnavailableError("AI servis eriÅŸilemez durumda")
        
        url = f"{self.base_url}{endpoint}"
        
        for attempt in range(self.config.retry_attempts):
            try:
                if not self.session:
                    await self.start()
                
                if method.upper() == "GET":
                    async with self.session.get(url) as response:
                        return await self._handle_response(response)
                
                elif method.upper() == "POST":
                    headers = {"Content-Type": "application/json"}
                    json_data = json.dumps(data) if data else None
                    
                    async with self.session.post(url, data=json_data, headers=headers) as response:
                        return await self._handle_response(response)
                
                else:
                    raise AIServiceError(f"Desteklenmeyen HTTP metod: {method}")
                    
            except aiohttp.ClientError as e:
                logger.warning(f"âš ï¸ AI servis istek hatasÄ± (deneme {attempt + 1}): {e}")
                
                if attempt == self.config.retry_attempts - 1:
                    raise AIServiceUnavailableError(f"AI servis {self.config.retry_attempts} denemeden sonra eriÅŸilemez")
                
                await asyncio.sleep(self.config.retry_delay * (attempt + 1))
        
        raise AIServiceError("Beklenmeyen hata")
    
    async def _handle_response(self, response: aiohttp.ClientResponse) -> Dict:
        """HTTP yanÄ±tÄ±nÄ± iÅŸle"""
        try:
            response_data = await response.json()
            
            if response.status == 200:
                return response_data
            
            elif response.status == 400:
                error_detail = response_data.get("detail", "GeÃ§ersiz istek")
                raise AIServiceError(f"GeÃ§ersiz istek: {error_detail}")
            
            elif response.status == 500:
                error_detail = response_data.get("detail", "Sunucu hatasÄ±")
                raise AIServiceError(f"AI servis hatasÄ±: {error_detail}")
            
            else:
                raise AIServiceError(f"Beklenmeyen yanÄ±t kodu: {response.status}")
                
        except json.JSONDecodeError:
            raise AIServiceError("GeÃ§ersiz JSON yanÄ±tÄ±")
    
    # AI Ä°ÅŸlemleri
    
    async def generate_embedding(self, text: str, force_turkish: bool = None) -> List[float]:
        """Metin iÃ§in embedding oluÅŸtur"""
        try:
            data = {
                "text": text,
                "force_turkish": force_turkish
            }
            
            response = await self._make_request("POST", "/embedding", data)
            return response["embedding"]
            
        except Exception as e:
            logger.error(f"Embedding oluÅŸturma hatasÄ±: {e}")
            raise AIServiceError(f"Embedding generation failed: {e}")
    
    async def generate_text(self, prompt: str, max_length: int = 80, turkish_context: bool = True) -> str:
        """Metin Ã¼ret"""
        try:
            data = {
                "prompt": prompt,
                "max_length": max_length,
                "turkish_context": turkish_context
            }
            
            response = await self._make_request("POST", "/generate", data)
            return response["generated_text"]
            
        except Exception as e:
            logger.error(f"Metin Ã¼retme hatasÄ±: {e}")
            raise AIServiceError(f"Text generation failed: {e}")
    
    async def generate_huggingface_response(self, message: str, user_id: str = None) -> str:
        """GeliÅŸmiÅŸ Hugging Face yanÄ±t Ã¼ret"""
        try:
            data = {
                "prompt": message,
                "max_length": 100,
                "turkish_context": True
            }
            
            response = await self._make_request("POST", "/generate/huggingface", data)
            return response["response"]
            
        except Exception as e:
            logger.error(f"Hugging Face yanÄ±t hatasÄ±: {e}")
            raise AIServiceError(f"Hugging Face response failed: {e}")
    
    async def detect_language(self, text: str) -> str:
        """Dil tanÄ±ma"""
        try:
            data = {"text": text}
            response = await self._make_request("POST", "/language/detect", data)
            return response["language"]
            
        except Exception as e:
            logger.error(f"Dil tanÄ±ma hatasÄ±: {e}")
            raise AIServiceError(f"Language detection failed: {e}")
    
    async def get_model_info(self) -> Dict[str, Any]:
        """Model bilgilerini al"""
        try:
            return await self._make_request("GET", "/models/info")
            
        except Exception as e:
            logger.error(f"Model bilgisi alma hatasÄ±: {e}")
            raise AIServiceError(f"Failed to get model info: {e}")
    
    async def warmup_models(self) -> bool:
        """Modelleri Ä±sÄ±t"""
        try:
            response = await self._make_request("POST", "/models/warmup")
            return "success" in response.get("message", "").lower()
            
        except Exception as e:
            logger.error(f"Model Ä±sÄ±tma hatasÄ±: {e}")
            return False
    
    async def cleanup_models(self) -> bool:
        """Model temizliÄŸi"""
        try:
            response = await self._make_request("POST", "/models/cleanup")
            return "success" in response.get("message", "").lower()
            
        except Exception as e:
            logger.error(f"Model temizlik hatasÄ±: {e}")
            return False
    
    async def get_service_health(self) -> Dict[str, Any]:
        """Servis saÄŸlÄ±k bilgilerini al"""
        try:
            return await self._make_request("GET", "/health")
            
        except Exception as e:
            logger.error(f"SaÄŸlÄ±k kontrolÃ¼ hatasÄ±: {e}")
            return {"status": "unhealthy", "error": str(e)}
    
    async def get_lazy_loading_stats(self) -> Dict[str, Any]:
        """Lazy loading istatistiklerini al"""
        try:
            response = await self._make_request("GET", "/stats/lazy-loading")
            return response["lazy_loading_stats"]
            
        except Exception as e:
            logger.error(f"Lazy loading istatistik hatasÄ±: {e}")
            return {}

# Global AI istemci instance
_ai_client = None

async def get_ai_client() -> AIServiceClient:
    """Global AI istemcisini al"""
    global _ai_client
    
    if _ai_client is None:
        _ai_client = AIServiceClient()
        await _ai_client.start()
    
    return _ai_client

async def close_ai_client():
    """Global AI istemcisini kapat"""
    global _ai_client
    
    if _ai_client:
        await _ai_client.close()
        _ai_client = None

# Fallback fonksiyonlarÄ± (AI servis eriÅŸilemezse)

class FallbackAIManager:
    """
    AI servis eriÅŸilemezse kullanÄ±lacak fallback manager
    """
    
    @staticmethod
    def generate_embedding_fallback(text: str) -> List[float]:
        """Basit embedding fallback"""
        # Basit hash-based embedding (gerÃ§ek projede sentence transformers kullan)
        import hashlib
        hash_obj = hashlib.md5(text.encode())
        hash_hex = hash_obj.hexdigest()
        
        # 384 boyutlu basit vektÃ¶r oluÅŸtur
        embedding = []
        for i in range(0, min(len(hash_hex), 96), 2):
            val = int(hash_hex[i:i+2], 16) / 255.0
            embedding.extend([val] * 4)  # Her hash byte'Ä± iÃ§in 4 float deÄŸer
        
        # 384'e tamamla
        while len(embedding) < 384:
            embedding.append(0.0)
        
        return embedding[:384]
    
    @staticmethod
    def generate_text_fallback(prompt: str) -> str:
        """Basit metin Ã¼retme fallback"""
        # Basit ÅŸablon yanÄ±tlar
        turkish_responses = [
            f"'{prompt}' konusunda size yardÄ±mcÄ± olmaya Ã§alÄ±ÅŸÄ±yorum. AI servisimiz ÅŸu anda bakÄ±mda.",
            f"Sorunuz '{prompt}' ile ilgili olarak, lÃ¼tfen biraz sonra tekrar deneyin.",
            f"'{prompt}' hakkÄ±nda detaylÄ± bilgi iÃ§in teknik ekibimizle iletiÅŸime geÃ§in.",
            "ÃœzgÃ¼nÃ¼m, ÅŸu anda AI servislerimiz geÃ§ici olarak kullanÄ±lamÄ±yor."
        ]
        
        import random
        return random.choice(turkish_responses)
    
    @staticmethod
    def detect_language_fallback(text: str) -> str:
        """Basit dil tanÄ±ma fallback"""
        turkish_chars = set('Ã§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄIÄ°Ã–ÅÃœ')
        has_turkish = any(char in turkish_chars for char in text)
        return 'turkish' if has_turkish else 'other'

# Wrapper fonksiyonlarÄ± - hem AI servis hem fallback desteÄŸi
async def safe_generate_embedding(text: str, force_turkish: bool = None) -> List[float]:
    """GÃ¼venli embedding Ã¼retimi (fallback destekli)"""
    try:
        client = await get_ai_client()
        return await client.generate_embedding(text, force_turkish)
    except (AIServiceUnavailableError, AIServiceError) as e:
        logger.warning(f"AI servis kullanÄ±lamÄ±yor, fallback kullanÄ±lÄ±yor: {e}")
        return FallbackAIManager.generate_embedding_fallback(text)

async def safe_generate_text(prompt: str, max_length: int = 80, turkish_context: bool = True) -> str:
    """GÃ¼venli metin Ã¼retimi (fallback destekli)"""
    try:
        client = await get_ai_client()
        return await client.generate_text(prompt, max_length, turkish_context)
    except (AIServiceUnavailableError, AIServiceError) as e:
        logger.warning(f"AI servis kullanÄ±lamÄ±yor, fallback kullanÄ±lÄ±yor: {e}")
        return FallbackAIManager.generate_text_fallback(prompt)

async def safe_generate_huggingface_response(message: str, user_id: str = None) -> str:
    """GÃ¼venli Hugging Face yanÄ±t Ã¼retimi (fallback destekli)"""
    try:
        client = await get_ai_client()
        return await client.generate_huggingface_response(message, user_id)
    except (AIServiceUnavailableError, AIServiceError) as e:
        logger.warning(f"AI servis kullanÄ±lamÄ±yor, fallback kullanÄ±lÄ±yor: {e}")
        return FallbackAIManager.generate_text_fallback(message)

async def safe_detect_language(text: str) -> str:
    """GÃ¼venli dil tanÄ±ma (fallback destekli)"""
    try:
        client = await get_ai_client()
        return await client.detect_language(text)
    except (AIServiceUnavailableError, AIServiceError) as e:
        logger.warning(f"AI servis kullanÄ±lamÄ±yor, fallback kullanÄ±lÄ±yor: {e}")
        return FallbackAIManager.detect_language_fallback(text)
