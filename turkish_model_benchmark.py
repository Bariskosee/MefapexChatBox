#!/usr/bin/env python3
"""
ğŸ‡¹ğŸ‡· MEFAPEX Turkish AI Model Performance Comparison
==================================================
Bu script farklÄ± TÃ¼rkÃ§e AI modellerinin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±r.
"""

import os
import sys
import time
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Any
import json

# Add current directory to path
sys.path.append(str(Path(__file__).parent))

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_model_performance(model_name: str, test_texts: List[str]) -> Dict[str, Any]:
    """Test a specific model's performance"""
    logger.info(f"ğŸ§ª Testing model: {model_name}")
    
    try:
        from sentence_transformers import SentenceTransformer
        import torch
        
        start_time = time.time()
        
        # Load model
        model = SentenceTransformer(model_name)
        load_time = time.time() - start_time
        
        # Test embeddings
        embedding_times = []
        embeddings = []
        
        for text in test_texts:
            embed_start = time.time()
            embedding = model.encode([text])
            embed_time = time.time() - embed_start
            embedding_times.append(embed_time)
            embeddings.append(embedding)
        
        # Calculate stats
        avg_embedding_time = sum(embedding_times) / len(embedding_times)
        total_test_time = sum(embedding_times)
        
        # Memory usage
        try:
            import psutil
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
        except ImportError:
            memory_mb = "N/A"
        
        # Model size estimation
        try:
            param_count = sum(p.numel() for p in model.parameters())
            model_size_mb = param_count * 4 / (1024 * 1024)  # Rough estimation
        except:
            model_size_mb = "N/A"
        
        # Clean up
        del model
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return {
            "model_name": model_name,
            "load_time_seconds": round(load_time, 3),
            "avg_embedding_time_seconds": round(avg_embedding_time, 3),
            "total_test_time_seconds": round(total_test_time, 3),
            "memory_usage_mb": round(memory_mb, 2) if isinstance(memory_mb, (int, float)) else memory_mb,
            "estimated_model_size_mb": round(model_size_mb, 2) if isinstance(model_size_mb, (int, float)) else model_size_mb,
            "embedding_dimension": len(embeddings[0][0]) if embeddings else "N/A",
            "status": "success"
        }
        
    except Exception as e:
        logger.error(f"âŒ Error testing {model_name}: {e}")
        return {
            "model_name": model_name,
            "status": "failed",
            "error": str(e)
        }

def compare_turkish_models():
    """Compare different Turkish and multilingual models"""
    logger.info("ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e AI Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ± BaÅŸlatÄ±lÄ±yor...")
    
    # Test texts in Turkish
    test_texts = [
        "Fabrika Ã§alÄ±ÅŸma saatleri nelerdir?",
        "Ä°zin baÅŸvurusu nasÄ±l yapÄ±lÄ±r?",
        "GÃ¼venlik kurallarÄ± hakkÄ±nda bilgi verir misiniz?",
        "Merhaba, nasÄ±l yardÄ±mcÄ± olabilirim?",
        "Vardiya deÄŸiÅŸiklikleri nasÄ±l yapÄ±lÄ±r?",
        "Yemek molasÄ± ne zaman baÅŸlÄ±yor?",
        "Acil durumlarda kimi aramam gerekiyor?",
        "Personel giriÅŸ Ã§Ä±kÄ±ÅŸ saatleri nedir?",
        "Teknik destek iÃ§in hangi numarayÄ± aramalÄ±yÄ±m?",
        "Proje yÃ¶netimi konusunda bilgi alabilir miyim?"
    ]
    
    # Models to test
    models_to_test = [
        # Turkish optimized models
        "emrecan/bert-base-turkish-cased-mean-nli-stsb-tr",
        
        # Multilingual models
        "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        "sentence-transformers/LaBSE",
        
        # Smaller multilingual models
        "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
        
        # English fallback (for comparison)
        "all-MiniLM-L6-v2",
        "all-mpnet-base-v2"
    ]
    
    results = []
    
    for model_name in models_to_test:
        logger.info(f"ğŸ”„ Testing: {model_name}")
        result = test_model_performance(model_name, test_texts)
        results.append(result)
        
        if result["status"] == "success":
            logger.info(f"âœ… {model_name}: "
                       f"Load: {result['load_time_seconds']}s, "
                       f"Avg Embed: {result['avg_embedding_time_seconds']}s, "
                       f"Memory: {result['memory_usage_mb']}MB")
        else:
            logger.error(f"âŒ {model_name}: {result.get('error', 'Unknown error')}")
        
        # Add delay between models to allow memory cleanup
        time.sleep(2)
    
    return results

def generate_report(results: List[Dict[str, Any]]):
    """Generate a detailed performance report"""
    logger.info("ğŸ“Š Rapor oluÅŸturuluyor...")
    
    # Filter successful results
    successful_results = [r for r in results if r["status"] == "success"]
    failed_results = [r for r in results if r["status"] == "failed"]
    
    # Sort by average embedding time
    successful_results.sort(key=lambda x: x["avg_embedding_time_seconds"])
    
    # Generate report
    report = {
        "test_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "total_models_tested": len(results),
        "successful_tests": len(successful_results),
        "failed_tests": len(failed_results),
        "results": results,
        "summary": {
            "fastest_model": successful_results[0]["model_name"] if successful_results else None,
            "slowest_model": successful_results[-1]["model_name"] if successful_results else None,
            "lowest_memory": min(successful_results, key=lambda x: x["memory_usage_mb"] if isinstance(x["memory_usage_mb"], (int, float)) else float('inf'))["model_name"] if successful_results else None,
            "highest_memory": max(successful_results, key=lambda x: x["memory_usage_mb"] if isinstance(x["memory_usage_mb"], (int, float)) else 0)["model_name"] if successful_results else None
        },
        "recommendations": []
    }
    
    # Add recommendations
    if successful_results:
        fastest = successful_results[0]
        report["recommendations"].append({
            "category": "En HÄ±zlÄ±",
            "model": fastest["model_name"],
            "reason": f"En dÃ¼ÅŸÃ¼k embedding sÃ¼resi: {fastest['avg_embedding_time_seconds']}s"
        })
        
        # Find Turkish-specific model
        turkish_models = [r for r in successful_results if "turkish" in r["model_name"].lower()]
        if turkish_models:
            best_turkish = turkish_models[0]
            report["recommendations"].append({
                "category": "TÃ¼rkÃ§e Optimize",
                "model": best_turkish["model_name"],
                "reason": "TÃ¼rkÃ§e diline Ã¶zel olarak eÄŸitilmiÅŸ"
            })
        
        # Find balanced model
        for result in successful_results:
            if (isinstance(result["memory_usage_mb"], (int, float)) and 
                result["memory_usage_mb"] < 2000 and 
                result["avg_embedding_time_seconds"] < 0.1):
                report["recommendations"].append({
                    "category": "Dengeli Performans",
                    "model": result["model_name"],
                    "reason": f"Ä°yi hÄ±z ({result['avg_embedding_time_seconds']}s) ve dÃ¼ÅŸÃ¼k bellek ({result['memory_usage_mb']}MB)"
                })
                break
    
    # Save report
    report_file = Path("turkish_model_performance_report.json")
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ğŸ“„ DetaylÄ± rapor kaydedildi: {report_file}")
    
    return report

def print_summary(report: Dict[str, Any]):
    """Print a summary of the performance test"""
    print("\n" + "="*70)
    print("ğŸ‡¹ğŸ‡· TÃœRKÃ‡E AI MODEL PERFORMANS RAPORU")
    print("="*70)
    
    print(f"ğŸ“… Test Tarihi: {report['test_timestamp']}")
    print(f"ğŸ§ª Test Edilen Model SayÄ±sÄ±: {report['total_models_tested']}")
    print(f"âœ… BaÅŸarÄ±lÄ± Testler: {report['successful_tests']}")
    print(f"âŒ BaÅŸarÄ±sÄ±z Testler: {report['failed_tests']}")
    
    print("\nğŸ“Š BAÅARILI MODELLER (HÄ±z SÄ±ralamasÄ±):")
    print("-" * 70)
    
    successful_results = [r for r in report["results"] if r["status"] == "success"]
    
    for i, result in enumerate(successful_results, 1):
        print(f"{i}. {result['model_name']}")
        print(f"   â±ï¸  YÃ¼kleme: {result['load_time_seconds']}s | Embedding: {result['avg_embedding_time_seconds']}s")
        print(f"   ğŸ’¾ Bellek: {result['memory_usage_mb']}MB | Boyut: {result['embedding_dimension']}D")
        print()
    
    if report["recommendations"]:
        print("ğŸ¯ Ã–NERÄ°LER:")
        print("-" * 70)
        for rec in report["recommendations"]:
            print(f"ğŸ† {rec['category']}: {rec['model']}")
            print(f"   ğŸ“ {rec['reason']}")
            print()
    
    if len(successful_results) > 0:
        print("ğŸ’¡ SONUÃ‡:")
        print("-" * 70)
        print("TÃ¼rkÃ§e dil desteÄŸi iÃ§in en iyi seÃ§enekler:")
        
        # Find best Turkish model
        turkish_models = [r for r in successful_results if "turkish" in r["model_name"].lower()]
        if turkish_models:
            print(f"1. ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e Optimize: {turkish_models[0]['model_name']}")
        
        # Find best multilingual
        multilingual = [r for r in successful_results if "multilingual" in r["model_name"].lower()]
        if multilingual:
            print(f"2. ğŸŒ Ã‡ok Dilli: {multilingual[0]['model_name']}")
        
        # Fastest overall
        print(f"3. âš¡ En HÄ±zlÄ±: {successful_results[0]['model_name']}")
        
        print("\nğŸ”§ KonfigÃ¼rasyon Ã¶nerisi:")
        print(f"TURKISH_SENTENCE_MODEL={turkish_models[0]['model_name'] if turkish_models else successful_results[0]['model_name']}")
        print(f"AI_PREFER_TURKISH_MODELS=true")
        print(f"AI_LANGUAGE_DETECTION=true")

def main():
    """Main function"""
    logger.info("ğŸš€ TÃ¼rkÃ§e AI Model Performans Testi BaÅŸlatÄ±lÄ±yor...")
    
    try:
        # Run comparison
        results = compare_turkish_models()
        
        # Generate report
        report = generate_report(results)
        
        # Print summary
        print_summary(report)
        
        logger.info("âœ… Performans testi tamamlandÄ±!")
        
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ Test kullanÄ±cÄ± tarafÄ±ndan iptal edildi")
    except Exception as e:
        logger.error(f"âŒ Test sÄ±rasÄ±nda hata: {e}")
        raise

if __name__ == "__main__":
    main()
