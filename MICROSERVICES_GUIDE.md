# ğŸ—ï¸ MEFAPEX Mikroservis Mimarisi

## Genel BakÄ±ÅŸ

MEFAPEX ChatBox artÄ±k mikroservis mimarisi kullanÄ±yor. AI iÅŸlemleri ayrÄ± bir servise Ã§Ä±karÄ±ldÄ± ve ana uygulama ile haberleÅŸiyor.

### Mimari BileÅŸenler

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MEFAPEX Mikroservis Mimarisi                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸŒ Client (Web Browser)                                        â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  ğŸš€ Ana Uygulama (Port 8000)                                   â”‚
â”‚     â”œâ”€ Web UI & API Gateway                                     â”‚
â”‚     â”œâ”€ Authentication & Session Management                      â”‚
â”‚     â”œâ”€ Database Operations                                      â”‚
â”‚     â””â”€ Static Content Management                                â”‚
â”‚         â”‚                                                       â”‚
â”‚         â”‚ HTTP/REST API                                         â”‚
â”‚         â–¼                                                       â”‚
â”‚  ğŸ¤– AI Mikroservisi (Port 8001)                                â”‚
â”‚     â”œâ”€ Embedding Generation                                     â”‚
â”‚     â”œâ”€ Text Generation                                          â”‚
â”‚     â”œâ”€ Language Detection                                       â”‚
â”‚     â””â”€ Model Management                                         â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“Š Ortak AltyapÄ±:                                              â”‚
â”‚     â”œâ”€ ğŸ—„ï¸ PostgreSQL Database                                   â”‚
â”‚     â”œâ”€ ğŸ” Qdrant Vector Database                                â”‚
â”‚     â””â”€ ğŸ—‚ï¸ Redis Cache                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Servis DetaylarÄ±

### ğŸš€ Ana Uygulama (Port 8000)

**GÃ¶revler:**
- Web arayÃ¼zÃ¼ sunma
- KullanÄ±cÄ± kimlik doÄŸrulama
- Session yÃ¶netimi
- Database operasyonlarÄ±
- Static content yÃ¶netimi
- AI servisi ile iletiÅŸim

**API Endpoints:**
- `GET /` - Ana sayfa
- `POST /login` - KullanÄ±cÄ± giriÅŸi
- `POST /chat` - Basit chat (kimlik doÄŸrulama gerektirmez)
- `POST /chat/authenticated` - Kimlik doÄŸrulamalÄ± chat
- `GET /health` - SaÄŸlÄ±k kontrolÃ¼
- `GET /docs` - API dokÃ¼mantasyonu

### ğŸ¤– AI Mikroservisi (Port 8001)

**GÃ¶revler:**
- AI model yÃ¶netimi
- Metin embedding Ã¼retimi
- Metin yanÄ±t Ã¼retimi
- Dil tanÄ±ma
- Model performans optimizasyonu

**API Endpoints:**
- `POST /embedding` - Embedding Ã¼retimi
- `POST /generate` - Temel metin Ã¼retimi
- `POST /generate/huggingface` - GeliÅŸmiÅŸ HuggingFace yanÄ±t
- `POST /language/detect` - Dil tanÄ±ma
- `GET /models/info` - Model bilgileri
- `POST /models/warmup` - Model Ä±sÄ±tma
- `POST /models/cleanup` - Model temizliÄŸi
- `GET /health` - SaÄŸlÄ±k kontrolÃ¼
- `GET /docs` - AI API dokÃ¼mantasyonu

## BaÅŸlatma SeÃ§enekleri

### 1. ğŸ³ Docker ile (Ã–nerilen)

```bash
# TÃ¼m servisleri Docker ile baÅŸlat
docker-compose up -d

# Sadece AI servisi
docker-compose up -d mefapex-ai

# LoglarÄ± izle
docker-compose logs -f
```

### 2. ğŸ”§ Manuel (Development)

```bash
# TÃ¼m mikroservisleri baÅŸlat
./start_microservices.sh

# Sadece AI servisini baÅŸlat
./start_ai_service.sh

# Ana uygulamayÄ± baÅŸlat (AI servisi Ã§alÄ±ÅŸÄ±rken)
python main.py
```

### 3. ğŸ› ï¸ AdÄ±m AdÄ±m

```bash
# 1. Gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# 2. AI mikroservisini baÅŸlat
python services/ai_service/main.py --host 0.0.0.0 --port 8001

# 3. Ana uygulamayÄ± baÅŸlat (yeni terminal)
export AI_SERVICE_ENABLED=true
export AI_SERVICE_HOST=127.0.0.1
export AI_SERVICE_PORT=8001
python main.py
```

## KonfigÃ¼rasyon

### Ortam DeÄŸiÅŸkenleri

```bash
# AI Mikroservis AyarlarÄ±
AI_SERVICE_ENABLED=true          # AI mikroservisi kullan/kullanma
AI_SERVICE_HOST=127.0.0.1        # AI servis host adresi
AI_SERVICE_PORT=8001             # AI servis portu

# Ana Uygulama AyarlarÄ±
DEBUG=true                       # Debug modu
ENVIRONMENT=development          # Ortam (development/production)
POSTGRES_HOST=localhost          # Database host
POSTGRES_PORT=5432              # Database port

# AI Modelleri
AI_MODELS_PATH=./models_cache    # Model cache dizini
TORCH_HOME=./models_cache/torch  # PyTorch model cache
HF_HOME=./models_cache/huggingface  # HuggingFace model cache
```

## Servis Ä°letiÅŸimi

### Ana Uygulama â†’ AI Servisi

Ana uygulama AI servisi ile HTTP REST API Ã¼zerinden iletiÅŸim kurar:

```python
# Ã–rnek: Embedding Ã¼retimi
async def generate_embedding(text: str):
    async with aiohttp.ClientSession() as session:
        async with session.post(
            "http://ai-service:8001/embedding",
            json={"text": text}
        ) as response:
            data = await response.json()
            return data["embedding"]
```

### Fallback MekanizmasÄ±

AI servisi eriÅŸilemezse, ana uygulama otomatik olarak yerel model manager'a geÃ§er:

```python
try:
    # AI servisi ile deneme
    result = await ai_client.generate_embedding(text)
except AIServiceUnavailableError:
    # Yerel model manager ile fallback
    result = local_model_manager.generate_embedding(text)
```

## Performans AvantajlarÄ±

### ğŸš€ Ã–lÃ§eklenebilirlik
- AI servisi baÄŸÄ±msÄ±z olarak Ã¶lÃ§eklendirilebilir
- Ana uygulama AI yÃ¼kÃ¼nden kurtuldu
- Her servis kendi kaynaklarÄ±nÄ± yÃ¶netir

### ğŸ§  HafÄ±za Optimizasyonu
- AI modelleri sadece AI servisinde yÃ¼klenir
- Ana uygulama hafÄ±za kullanÄ±mÄ± %60-70 azaldÄ±
- Model cache'i merkezi olarak yÃ¶netilir

### âš¡ YanÄ±t SÃ¼releri
- AI iÅŸlemleri paralel olarak Ã§alÄ±ÅŸabilir
- Ana uygulama blocking olmadan Ã§alÄ±ÅŸÄ±r
- Lazy loading optimize edildi

### ğŸ”’ GÃ¼venlik
- AI servisi internal network'te Ã§alÄ±ÅŸÄ±r
- API rate limiting baÄŸÄ±msÄ±z olarak uygulanÄ±r
- Servis izolasyonu saÄŸlandÄ±

## Monitoring ve Logging

### SaÄŸlÄ±k Kontrolleri

```bash
# Ana uygulama saÄŸlÄ±ÄŸÄ±
curl http://localhost:8000/health

# AI servisi saÄŸlÄ±ÄŸÄ±
curl http://localhost:8001/health

# DetaylÄ± AI model bilgileri
curl http://localhost:8001/models/info
```

### Log DosyalarÄ±

```
logs/
â”œâ”€â”€ main_app_YYYYMMDD_HHMMSS.log    # Ana uygulama
â”œâ”€â”€ ai_service_YYYYMMDD_HHMMSS.log  # AI mikroservisi
â””â”€â”€ docker_compose.log              # Docker loglarÄ±
```

### Performans Metrikleri

```bash
# AI servis istatistikleri
curl http://localhost:8001/stats/lazy-loading

# Model bilgileri
curl http://localhost:8001/models/info

# Ana uygulama saÄŸlÄ±k durumu
curl http://localhost:8000/api/health
```

## Troubleshooting

### ğŸ”§ YaygÄ±n Problemler

**AI Servisi BaÅŸlamÄ±yor:**
```bash
# BaÄŸÄ±mlÄ±lÄ±klarÄ± kontrol et
pip install aiohttp

# Port Ã§akÄ±ÅŸmasÄ± kontrol et
lsof -i :8001

# Manuel baÅŸlatma
python services/ai_service/main.py --host 0.0.0.0 --port 8001
```

**Ana Uygulama AI Servisine BaÄŸlanamÄ±yor:**
```bash
# AI servis durumunu kontrol et
curl http://localhost:8001/health

# Network baÄŸlantÄ±sÄ±nÄ± test et
telnet localhost 8001

# Fallback moda geÃ§
export AI_SERVICE_ENABLED=false
```

**Model YÃ¼kleme SorunlarÄ±:**
```bash
# Model cache'i temizle
rm -rf models_cache/*

# Modelleri yeniden indir
curl -X POST http://localhost:8001/models/warmup

# HafÄ±za kullanÄ±mÄ±nÄ± kontrol et
curl http://localhost:8001/models/info
```

### ğŸ“Š Debug KomutlarÄ±

```bash
# TÃ¼m servislerin durumu
ps aux | grep python | grep -E "(main.py|ai_service)"

# Port kullanÄ±mÄ±
netstat -tulpn | grep -E "(8000|8001)"

# Log takibi
tail -f logs/*.log

# Docker container durumu
docker-compose ps
docker-compose logs mefapex-ai
```

## Migration Rehberi

### Mevcut Kurulumdan Mikroservise GeÃ§iÅŸ

1. **Backup AlÄ±n:**
```bash
cp -r . ../mefapex_backup_$(date +%Y%m%d)
```

2. **Yeni Kodu GÃ¼ncelleyin:**
```bash
git pull origin main
```

3. **BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin:**
```bash
pip install -r requirements.txt
```

4. **Mikroservisleri BaÅŸlatÄ±n:**
```bash
./start_microservices.sh
```

5. **Test Edin:**
```bash
curl http://localhost:8000/health
curl http://localhost:8001/health
```

## Ä°leri DÃ¼zey KonfigÃ¼rasyon

### Load Balancing

Ã‡oklu AI servisi Ã§alÄ±ÅŸtÄ±rma:
```bash
# Port 8001, 8002, 8003'te AI servisleri baÅŸlat
python services/ai_service/main.py --port 8001 &
python services/ai_service/main.py --port 8002 &
python services/ai_service/main.py --port 8003 &
```

### Service Discovery

Docker Compose ile otomatik service discovery:
```yaml
environment:
  - AI_SERVICE_HOST=mefapex-ai
  - AI_SERVICE_PORT=8001
```

### Monitoring Stack

Production iÃ§in Prometheus + Grafana:
```bash
docker-compose --profile production up -d
```

---

## ğŸ“ Destek

Mikroservis mimarisi ile ilgili sorularÄ±nÄ±z iÃ§in:
- ğŸ“– DokÃ¼mantasyon: `/docs` endpoints
- ğŸ› Issue tracking: GitHub Issues
- ğŸ“§ Teknik destek: Proje ekibi
