#!/usr/bin/env python3
"""
ğŸš€ Cache Performance Test for MEFAPEX Chat API
=============================================
Bu script chat API'sÄ±nÄ±n cache performansÄ±nÄ± test eder ve hatalarÄ± kontrol eder.
"""

import asyncio
import json
import time
import logging
from pathlib import Path
import sys

# Add current directory to path
sys.path.append(str(Path(__file__).parent))

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_cache_performance():
    """Test cache performance and functionality"""
    
    try:
        # Import modules
        from response_cache import response_cache
        from api.chat import generate_ai_response
        
        logger.info("ğŸ§ª Cache Performance Test BaÅŸlatÄ±lÄ±yor...")
        
        # Test messages
        test_messages = [
            "Merhaba",
            "Fabrika Ã§alÄ±ÅŸma saatleri nelerdir?",
            "Ä°zin baÅŸvurusu nasÄ±l yapÄ±lÄ±r?",
            "GÃ¼venlik kurallarÄ± nelerdir?",
            "Yapay zeka hakkÄ±nda bilgi ver",
            "Python nedir?",
            "MEFAPEX hakkÄ±nda bilgi ver",
            "Ã‡alÄ±ÅŸma sÃ¼releri",
            "Hello",
            "What are working hours?"
        ]
        
        # Clear cache for clean test
        response_cache.clear()
        logger.info("ğŸ—‘ï¸ Cache temizlendi")
        
        # Test 1: Cache miss performance
        logger.info("ğŸ“Š Test 1: Cache Miss Performance")
        cache_miss_times = []
        
        for i, message in enumerate(test_messages):
            start_time = time.time()
            
            # Check cache (should be miss)
            cached = response_cache.get(message)
            assert cached is None, f"Cache should be empty for: {message}"
            
            # Generate response
            try:
                response, source = await generate_ai_response(message)
                
                # Cache the response
                response_cache.set(message, response, source=source)
                
                end_time = time.time()
                duration = (end_time - start_time) * 1000  # ms
                cache_miss_times.append(duration)
                
                logger.info(f"  {i+1:2d}. {message[:30]:30} -> {duration:6.1f}ms ({source})")
                
            except Exception as e:
                logger.error(f"Error generating response for '{message}': {e}")
                continue
        
        avg_miss_time = sum(cache_miss_times) / len(cache_miss_times)
        logger.info(f"âœ… Ortalama cache miss sÃ¼resi: {avg_miss_time:.1f}ms")
        
        # Test 2: Cache hit performance
        logger.info("ğŸ“Š Test 2: Cache Hit Performance")
        cache_hit_times = []
        
        for i, message in enumerate(test_messages):
            start_time = time.time()
            
            # Check cache (should be hit)
            cached = response_cache.get(message)
            
            if cached:
                response, source = cached
                logger.debug(f"Cache hit: {source}")
            else:
                logger.warning(f"Unexpected cache miss for: {message}")
                continue
            
            end_time = time.time()
            duration = (end_time - start_time) * 1000  # ms
            cache_hit_times.append(duration)
            
            logger.info(f"  {i+1:2d}. {message[:30]:30} -> {duration:6.1f}ms (cache_{source})")
        
        avg_hit_time = sum(cache_hit_times) / len(cache_hit_times)
        logger.info(f"âœ… Ortalama cache hit sÃ¼resi: {avg_hit_time:.1f}ms")
        
        # Test 3: Performance improvement
        if avg_hit_time > 0 and avg_miss_time > 0:
            improvement = (avg_miss_time / avg_hit_time)
            logger.info(f"ğŸš€ Cache performans kazancÄ±: {improvement:.1f}x daha hÄ±zlÄ±")
        
        # Test 4: Cache statistics
        logger.info("ğŸ“Š Test 4: Cache Ä°statistikleri")
        stats = response_cache.get_stats()
        
        logger.info("Cache Ä°statistikleri:")
        for key, value in stats.items():
            logger.info(f"  {key}: {value}")
        
        # Test 5: Cache functionality verification
        logger.info("ğŸ“Š Test 5: Cache Fonksiyonalite KontrolÃ¼")
        
        # Test tuple return
        test_msg = "Test mesajÄ±"
        response_cache.set(test_msg, "Test cevabÄ±", source="test")
        cached_result = response_cache.get(test_msg)
        
        assert cached_result is not None, "Cache should return result"
        assert isinstance(cached_result, tuple), "Cache should return tuple"
        assert len(cached_result) == 2, "Cache should return (response, source) tuple"
        
        cached_response, cached_source = cached_result
        assert cached_response == "Test cevabÄ±", "Response should match"
        assert cached_source == "test", "Source should match"
        
        logger.info("âœ… Cache tuple return functionality verified")
        
        # Test 6: Memory usage
        logger.info("ğŸ“Š Test 6: Bellek KullanÄ±mÄ±")
        memory_usage = stats.get('memory_usage_mb', 0)
        logger.info(f"Cache bellek kullanÄ±mÄ±: {memory_usage:.2f} MB")
        
        # Test 7: Popular entries
        logger.info("ğŸ“Š Test 7: PopÃ¼ler Cache GiriÅŸleri")
        popular = response_cache.get_popular_entries(5)
        
        for i, entry in enumerate(popular, 1):
            logger.info(f"  {i}. {entry['key']} - {entry['access_count']} eriÅŸim - {entry['source']}")
        
        # Summary
        logger.info("=" * 60)
        logger.info("ğŸ‰ CACHE PERFORMANCE TEST SONUÃ‡LARI")
        logger.info("=" * 60)
        logger.info(f"ğŸ“¦ Cache Boyutu: {stats['size']} / {stats['max_size']}")
        logger.info(f"ğŸ¯ Hit Rate: {stats['hit_rate']:.1f}%")
        logger.info(f"âš¡ Cache Miss Ortalama: {avg_miss_time:.1f}ms")
        logger.info(f"ğŸš€ Cache Hit Ortalama: {avg_hit_time:.1f}ms")
        if avg_hit_time > 0 and avg_miss_time > 0:
            logger.info(f"ğŸ“ˆ Performans KazancÄ±: {improvement:.1f}x")
        logger.info(f"ğŸ’¾ Bellek KullanÄ±mÄ±: {memory_usage:.2f} MB")
        logger.info("=" * 60)
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_api_integration():
    """Test API integration with corrected cache usage"""
    
    logger.info("ğŸ”Œ API Integration Test BaÅŸlatÄ±lÄ±yor...")
    
    try:
        from api.chat import chat_message
        from pydantic import BaseModel
        from unittest.mock import Mock
        
        # Mock request and user
        mock_request = Mock()
        mock_request.client.host = "127.0.0.1"
        
        mock_user = {"user_id": "test_user_123"}
        
        # Test message
        class TestChatMessage(BaseModel):
            message: str
        
        test_msg = TestChatMessage(message="Test API mesajÄ±")
        
        # First call (cache miss)
        logger.info("ğŸ“¤ Ä°lk API Ã§aÄŸrÄ±sÄ± (cache miss)...")
        start_time = time.time()
        try:
            response1 = await chat_message(test_msg, mock_request, mock_user)
            miss_time = (time.time() - start_time) * 1000
            logger.info(f"âœ… Ä°lk Ã§aÄŸrÄ±: {miss_time:.1f}ms - Source: {response1.source}")
        except Exception as e:
            logger.warning(f"API test skipped due to dependencies: {e}")
            return True
        
        # Second call (cache hit)
        logger.info("ğŸ“¥ Ä°kinci API Ã§aÄŸrÄ±sÄ± (cache hit)...")
        start_time = time.time()
        response2 = await chat_message(test_msg, mock_request, mock_user)
        hit_time = (time.time() - start_time) * 1000
        logger.info(f"âœ… Ä°kinci Ã§aÄŸrÄ±: {hit_time:.1f}ms - Source: {response2.source}")
        
        # Verify cache was used
        assert "cache_" in response2.source, f"Expected cached response, got: {response2.source}"
        
        # Verify response consistency
        assert response1.response == response2.response, "Cached response should be identical"
        
        # Performance check
        if hit_time > 0:
            improvement = miss_time / hit_time
            logger.info(f"ğŸš€ API Cache kazancÄ±: {improvement:.1f}x daha hÄ±zlÄ±")
        
        logger.info("âœ… API Integration test passed")
        return True
        
    except Exception as e:
        logger.error(f"âŒ API Integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """Main test function"""
    logger.info("ğŸ§ª MEFAPEX Cache Performance Test Suite")
    logger.info("=" * 60)
    
    tests_passed = 0
    total_tests = 2
    
    # Test 1: Cache Performance
    if await test_cache_performance():
        tests_passed += 1
        logger.info("âœ… Cache Performance Test: PASSED")
    else:
        logger.error("âŒ Cache Performance Test: FAILED")
    
    # Test 2: API Integration
    if await test_api_integration():
        tests_passed += 1
        logger.info("âœ… API Integration Test: PASSED")
    else:
        logger.error("âŒ API Integration Test: FAILED")
    
    # Summary
    logger.info("=" * 60)
    logger.info(f"ğŸ TEST SONUÃ‡LARI: {tests_passed}/{total_tests} test passed")
    
    if tests_passed == total_tests:
        logger.info("ğŸ‰ TÃœM TESTLER BAÅARILI!")
        return True
    else:
        logger.error("ğŸ’¥ BAZI TESTLER BAÅARISIZ!")
        return False

if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("â¹ï¸ Test kullanÄ±cÄ± tarafÄ±ndan iptal edildi")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ Beklenmeyen hata: {e}")
        sys.exit(1)
