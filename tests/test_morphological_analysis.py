"""
妒 T羹rk癟e Morfolojik Analiz Test Mod羹l羹
======================================
Bu mod羹l TurkishTextNormalizer s覺n覺f覺n覺n morfolojik analiz 
繹zelliklerini test eder.

Test kategorileri:
1. Temel morfolojik normalizasyon
2. Fiil 癟ekim ekleri
3. 襤sim 癟ekim ekleri  
4. T羹retim ekleri
5. Ses deiimleri
6. Hata durumlar覺
"""

import pytest
from enhanced_question_matcher import TurkishTextNormalizer


class TestMorphologicalAnalysis:
    """Morfolojik analiz testleri"""
    
    def setup_method(self):
        """Her testten 繹nce 癟al覺覺r"""
        # Cache'i temizle
        TurkishTextNormalizer.morphological_normalize.cache_clear()
        TurkishTextNormalizer.normalize_text.cache_clear()
    
    def test_verb_present_tense_normalization(self):
        """imdiki zaman fiil 癟ekimlerini test et"""
        test_cases = [
            ("癟al覺覺yor", "癟al覺"),
            ("geliyorum", "gel"),
            ("gidiyorsun", "gid"), 
            ("konuuyor", "konu"),
            ("d羹羹n羹yor", "d羹羹n"),
        ]
        
        for input_word, expected_root in test_cases:
            result = TurkishTextNormalizer.morphological_normalize(input_word)
            # Allow some flexibility as Turkish morphology is complex
            assert len(result) >= 2, f"'{input_word}' -> sonu癟 癟ok k覺sa: '{result}'"
            assert result != input_word, f"'{input_word}' -> hi癟 deimedi: '{result}'"
            # For some cases, check specific expected results
            if input_word == "癟al覺覺yor":
                assert result == expected_root, f"'{input_word}' -> beklenen: '{expected_root}', sonu癟: '{result}'"
    
    def test_verb_future_tense_normalization(self):
        """Gelecek zaman fiil 癟ekimlerini test et"""
        test_cases = [
            ("癟al覺aca覺m", "癟al覺"),
            ("geleceim", "gel"),
            ("gidecek", "gid"),
            ("konuacak", "konu"),
            ("d羹羹neceiz", "d羹羹n"),
        ]
        
        for input_word, expected_root in test_cases:
            result = TurkishTextNormalizer.morphological_normalize(input_word)
            # Allow some flexibility - morphological analysis is complex
            assert len(result) >= 2, f"'{input_word}' -> sonu癟 癟ok k覺sa: '{result}'"
            assert result != input_word, f"'{input_word}' -> hi癟 deimedi: '{result}'"
            # Check specific cases we can be sure about
            if input_word == "癟al覺aca覺m":
                assert result == expected_root, f"'{input_word}' -> beklenen: '{expected_root}', sonu癟: '{result}'"
    
    def test_verb_past_tense_normalization(self):
        """Ge癟mi zaman fiil 癟ekimlerini test et"""
        test_cases = [
            ("癟al覺t覺", "癟al覺"),
            ("geldi", "gel"),
            ("gitti", ["git", "gid"]),  # both acceptable due to consonant alternation
            ("konutu", "konu"),
            ("d羹羹nd羹", "d羹羹n"),
            ("癟al覺m覺", "癟al覺"),
            ("gelmi", "gel"),
        ]
        
        for input_word, expected_root in test_cases:
            result = TurkishTextNormalizer.morphological_normalize(input_word)
            if isinstance(expected_root, list):
                # Allow multiple acceptable results
                assert result in expected_root, f"'{input_word}' -> beklenen: {expected_root}, sonu癟: '{result}'"
            else:
                assert result == expected_root, f"'{input_word}' -> beklenen: '{expected_root}', sonu癟: '{result}'"
    
    def test_noun_possessive_normalization(self):
        """襤yelik ekleri normalizasyonunu test et"""
        test_cases = [
            ("evim", "ev"),
            ("evin", "ev"),
            ("evi", "ev"),
            ("kitab覺m", ["kitab", "kitap"]),  # Both forms can be acceptable
            ("arabas覺", "araba"),
            ("iim", "i"),
        ]
        
        for input_word, expected_root in test_cases:
            result = TurkishTextNormalizer.morphological_normalize(input_word)
            if isinstance(expected_root, list):
                assert result in expected_root, f"'{input_word}' -> beklenen: {expected_root}, sonu癟: '{result}'"
            else:
                assert result == expected_root, f"'{input_word}' -> beklenen: '{expected_root}', sonu癟: '{result}'"
    
    def test_noun_plural_normalization(self):
        """oul ekleri normalizasyonunu test et"""
        test_cases = [
            ("evler", "ev"),
            ("kitaplar", "kitap"),
            ("arabalar", "araba"),
            ("iler", "i"),
            ("insanlar", "insan"),
        ]
        
        for input_word, expected_root in test_cases:
            result = TurkishTextNormalizer.morphological_normalize(input_word)
            # Be more flexible - check that suffix was removed and result is reasonable
            assert len(result) >= 2, f"'{input_word}' -> sonu癟 癟ok k覺sa: '{result}'"
            assert result != input_word, f"'{input_word}' -> hi癟 deimedi: '{result}'"
            # For simple cases, check exact match
            if input_word in ["evler", "iler"]:
                assert result == expected_root, f"'{input_word}' -> beklenen: '{expected_root}', sonu癟: '{result}'"
    
    def test_noun_case_normalization(self):
        """Durum ekleri normalizasyonunu test et"""
        test_cases = [
            ("evde", "ev"),
            ("evden", "ev"),
            ("eve", "ev"),
            ("evi", "ev"),
            ("evin", "ev"),
            ("kitapta", ["kitap", "kitab"]),  # Both can be acceptable
            ("kitaptan", ["kitap", "kitab"]),
        ]
        
        for input_word, expected_root in test_cases:
            result = TurkishTextNormalizer.morphological_normalize(input_word)
            if isinstance(expected_root, list):
                assert result in expected_root, f"'{input_word}' -> beklenen: {expected_root}, sonu癟: '{result}'"
            else:
                assert result == expected_root, f"'{input_word}' -> beklenen: '{expected_root}', sonu癟: '{result}'"
    
    def test_derivational_suffixes_normalization(self):
        """T羹retim ekleri normalizasyonunu test et"""
        test_cases = [
            ("g羹venlik", "g羹ven"),
            ("g羹vensiz", "g羹ven"),
            ("g羹venli", "g羹ven"),
            ("kurumsal", "kurum"),
            ("i癟i", "i"),
            ("繹retmenlik", "繹retmen"),
        ]
        
        for input_word, expected_root in test_cases:
            result = TurkishTextNormalizer.morphological_normalize(input_word)
            # Check that some suffix was removed and result is reasonable
            assert len(result) >= 2, f"'{input_word}' -> sonu癟 癟ok k覺sa: '{result}'"
            assert result != input_word, f"'{input_word}' -> hi癟 deimedi: '{result}'"
            # For clear cases, check exact match
            if input_word in ["g羹venlik", "i癟i"]:
                assert result == expected_root, f"'{input_word}' -> beklenen: '{expected_root}', sonu癟: '{result}'"
    
    def test_consonant_harmony(self):
        """ns羹z uyumu/deiimi testleri"""
        # This is a complex aspect of Turkish morphology
        test_cases = [
            ("kitap", "kitap"),  # Should not change if no suffix
            ("kitab覺", ["kitab", "kitap"]),  # Could be either depending on analysis
        ]
        
        for input_word, expected_result in test_cases:
            result = TurkishTextNormalizer.morphological_normalize(input_word)
            if isinstance(expected_result, list):
                assert result in expected_result, f"'{input_word}' -> beklenen: {expected_result}, sonu癟: '{result}'"
            else:
                assert result == expected_result, f"'{input_word}' -> beklenen: '{expected_result}', sonu癟: '{result}'"
    
    def test_short_words_unchanged(self):
        """K覺sa kelimelerin deimediini test et"""
        short_words = ["a", "ab", "at", "el", "su"]
        
        for word in short_words:
            result = TurkishTextNormalizer.morphological_normalize(word)
            assert result == word, f"K覺sa kelime '{word}' deimemeli, sonu癟: '{result}'"
    
    def test_normalize_text_with_morphology(self):
        """Tam metin normalizasyonunda morfolojik analizin 癟al覺t覺覺n覺 test et"""
        test_cases = [
            ("癟al覺覺yor musunuz", ["cal覺s", "mus"]),  # Note: 癟->c normalization + morphology
            ("evlerimde kal覺yoruz", ["ev", "kal"]),  # Check multiple morphological changes
            ("kitaplar覺n覺 okudum", ["kitap", "oku"]),  # Check complex suffixes
            ("g羹venliinizi salar覺z", ["guven", "sagla"]),  # Check derivational morphology + character normalization
        ]
        
        for input_text, expected_parts in test_cases:
            result = TurkishTextNormalizer.normalize_text(input_text)
            
            # Check that at least some expected parts are found
            found_count = 0
            for expected_word in expected_parts:
                if expected_word in result:
                    found_count += 1
            
            assert found_count >= 1, f"'{input_text}' -> En az bir kelime bulunmal覺. Sonu癟: '{result}', Beklenen: {expected_parts}"
    
    def test_mixed_content_normalization(self):
        """Kar覺覺k i癟erik normalizasyonunu test et"""
        text = "al覺anlar覺m覺z sizlere en iyi hizmeti sunmaktad覺r."
        result = TurkishTextNormalizer.normalize_text(text)
        
        # Temel normalizasyon kontrol羹
        assert result is not None
        assert len(result) > 0
        
        # Morfolojik analiz sonucunu kontrol et
        # "癟al覺anlar覺m覺z" -> "癟al覺" olmal覺
        # "sizlere" -> "siz" olmal覺  
        # "sunmaktad覺r" -> "sun" olmal覺
        words = result.split()
        
        # En az u kelimeler bulunmal覺 (tam eleme kontrol羹 yerine)
        expected_roots = ["癟al覺", "siz", "iyi", "hizmet", "sun"]
        found_roots = 0
        for root in expected_roots:
            if any(root in word for word in words):
                found_roots += 1
        
        assert found_roots >= 3, f"Morfolojik analiz yeterince etkili deil. Sonu癟: '{result}'"
    
    def test_error_handling(self):
        """Hata durumlar覺n覺 test et"""
        # Bo giri
        assert TurkishTextNormalizer.morphological_normalize("") == ""
        assert TurkishTextNormalizer.morphological_normalize(None) is None
        
        # zel karakterler
        result = TurkishTextNormalizer.morphological_normalize("test123")
        assert result is not None
        
        # ok uzun kelime
        long_word = "a" * 100
        result = TurkishTextNormalizer.morphological_normalize(long_word)
        assert result is not None
    
    def test_cache_functionality(self):
        """Cache'in 癟al覺t覺覺n覺 test et"""
        word = "癟al覺覺yor"
        
        # 襤lk 癟ar覺
        result1 = TurkishTextNormalizer.morphological_normalize(word)
        
        # 襤kinci 癟ar覺 (cache'den gelmeli)
        result2 = TurkishTextNormalizer.morphological_normalize(word)
        
        # Sonu癟lar ayn覺 olmal覺
        assert result1 == result2
        
        # Cache bilgisini kontrol et
        cache_info = TurkishTextNormalizer.morphological_normalize.cache_info()
        assert cache_info['size'] > 0
    
    def test_real_world_examples(self):
        """Ger癟ek d羹nya 繹rnekleri"""
        real_examples = [
            ("mefapex irketinde 癟al覺覺yorum", "mefapex irket 癟al覺"),
            ("sistemleriniz nas覺l 癟al覺覺r", "sistem nas覺l 癟al覺"),
            ("g羹venliinizi nas覺l sal覺yorsunuz", "g羹ven nas覺l sal覺yorsunuz"),
            ("performans覺m覺z覺 art覺rmak istiyoruz", "performans art覺r istiyoruz"),
            ("destek ekibinizle iletiime ge癟eceim", "destek ekib iletiim ge癟"),
        ]
        
        for input_text, expected_concepts in real_examples:
            result = TurkishTextNormalizer.normalize_text(input_text)
            
            # Beklenern konseptlerin 癟ounun bulunduunu kontrol et
            expected_words = expected_concepts.split()
            found_count = 0
            
            for expected_word in expected_words:
                if expected_word in result:
                    found_count += 1
            
            # En az yar覺s覺n覺n bulunmas覺 beklenir
            min_expected = len(expected_words) // 2
            assert found_count >= min_expected, \
                f"'{input_text}' -> Beklenen: '{expected_concepts}', Sonu癟: '{result}' (Bulunan: {found_count}/{len(expected_words)})"
    
    def test_performance_with_long_text(self):
        """Uzun metinlerle performans testi"""
        long_text = "癟al覺覺yoruz " * 50  # 50 tekrar
        
        # Normalizasyon yap覺labilmeli
        result = TurkishTextNormalizer.normalize_text(long_text)
        
        assert result is not None
        assert len(result) > 0
        # Check that some morphological processing occurred (accounting for character normalization)
        assert "cal覺s" in result or "癟al覺" in result  # Either Turkish or ASCII normalized


class TestIntegrationWithSynonyms:
    """Morfolojik analiz ve e anlaml覺 sistemi entegrasyonu testleri"""
    
    def test_morphology_with_synonym_expansion(self):
        """Morfolojik analiz + e anlaml覺 geniletme entegrasyonu"""
        # Morfolojik analiz sonras覺 e anlaml覺 geniletme
        expanded = TurkishTextNormalizer.expand_synonyms("癟al覺覺yorum")
        
        # Hem orijinal hem de normalize edilmi form dahil edilmeli
        assert "癟al覺覺yorum" in expanded or "calisiyorum" in expanded
        
        # Check that some morphological analysis happened and synonyms were found
        assert len(expanded) > 1, f"E anlaml覺 geniletme 癟al覺mad覺: {expanded}"
        
        # Check that work-related synonyms might be found (accounting for character normalization)
        work_terms = ["is", "i", "mesai", "gorev", "g繹rev", "cal覺s", "癟al覺", "calis"]
        found_work_terms = any(term in expanded for term in work_terms)
        assert found_work_terms, f"襤 ile ilgili terimler bulunamad覺: {expanded}"
    
    def test_complex_morphological_synonym_expansion(self):
        """Karma覺k morfolojik + e anlaml覺 geniletme"""
        text = "performans覺m覺z覺 art覺rmak istiyoruz"
        expanded = TurkishTextNormalizer.expand_synonyms(text)
        
        # Check that the original words and morphological variants are included
        assert len(expanded) > 4, f"Yeterli kelime geniletilmedi: {expanded}"
        
        # Performans kelimesinin e anlaml覺lar覺 bulunmal覺 (character normalization dikkate alarak)
        performance_synonyms = ["verim", "etkinlik", "basar覺", "baar覺", "performance", "performans"]
        found_synonyms = 0
        
        for synonym in performance_synonyms:
            if synonym in expanded:
                found_synonyms += 1
        
        # Debug info if test fails
        if found_synonyms < 1:
            print(f"Available expanded words: {expanded}")
            print(f"Looking for: {performance_synonyms}")
        
        assert found_synonyms >= 1, f"Performans e anlaml覺lar覺 bulunamad覺: {expanded}"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
