"""
ðŸ§  GeliÅŸmiÅŸ TÃ¼rkÃ§e Soru Anlama ve EÅŸleÅŸtirme Sistemi
================================================================
Fuzzy matching, semantic similarity ve NLP teknikleri ile geliÅŸmiÅŸ soru-cevap eÅŸleÅŸtirmesi

Bu sistem, banka uygulamalarÄ±ndaki chatbot asistanlarÄ± gibi akÄ±llÄ± soru anlama Ã¶zelliÄŸi saÄŸlar.
"""

import re
import hashlib
import logging
import unicodedata
from typing import List, Dict, Tuple, Optional, Set
from dataclasses import dataclass
from functools import lru_cache
from difflib import SequenceMatcher
import numpy as np

logger = logging.getLogger(__name__)

@dataclass
class QuestionMatch:
    """Soru eÅŸleÅŸtirme sonucu"""
    original_question: str
    matched_content: str
    similarity_score: float
    matching_keywords: List[str]
    match_type: str  # fuzzy, semantic, keyword, exact
    confidence: float
    response: str
    category: str

class TurkishTextNormalizer:
    """TÃ¼rkÃ§e metin normalizasyonu ve temizleme"""
    
    # TÃ¼rkÃ§e karakter dÃ¶nÃ¼ÅŸÃ¼mleri
    TURKISH_CHAR_MAP = {
        'Ã§': 'c', 'ÄŸ': 'g', 'Ä±': 'i', 'Ã¶': 'o', 'ÅŸ': 's', 'Ã¼': 'u',
        'Ã‡': 'C', 'Äž': 'G', 'I': 'I', 'Ä°': 'I', 'Ã–': 'O', 'Åž': 'S', 'Ãœ': 'U'
    }
    
    # EÅŸ anlamlÄ± kelimeler (synonyms) - MEFAPEX iÃ§in Ã¶zelleÅŸtirilmiÅŸ
    SYNONYMS = {
        'Ã§alÄ±ÅŸma': ['iÅŸ', 'mesai', 'gÃ¶rev', 'faaliyet', 'iÅŸ saatleri', 'working', 'work', 'job'],
        'saat': ['zaman', 'vakit', 'sÃ¼re', 'time', 'hours', 'hour', 'saat kaÃ§', 'ne zaman'],
        'saatleri': ['zamanlarÄ±', 'vakitleri', 'hours', 'times'],
        'aÃ§Ä±k': ['open', 'aÃ§Ä±lÄ±ÅŸ', 'baÅŸlama', 'start'],
        'kapalÄ±': ['closed', 'kapanÄ±ÅŸ', 'bitiÅŸ', 'end'],
        'nedir': ['ne', 'nelerdir', 'hangi', 'nasÄ±l', 'what', 'which', 'kim'],
        'gÃ¼venlik': ['emniyet', 'koruma', 'security', 'safety'],
        'kural': ['yÃ¶netmelik', 'prosedÃ¼r', 'talimat', 'rule', 'regulation'],
        'destek': ['yardÄ±m', 'assistance', 'help', 'support'],
        'sistem': ['platform', 'uygulama', 'yazÄ±lÄ±m', 'system', 'software'],
        'personel': ['Ã§alÄ±ÅŸan', 'iÅŸÃ§i', 'employee', 'staff', 'worker'],
        'fabrika': ['tesis', 'imalathane', 'Ã¼retim', 'factory', 'plant', 'manufacturing'],
        'mefapex': ['ÅŸirket', 'firma', 'company'],
        'teknoloji': ['technology', 'tech', 'biliÅŸim', 'it'],
        'hizmet': ['service', 'servis'],
        'proje': ['project'],
        'yazÄ±lÄ±m': ['software', 'program'],
        'uygulama': ['application', 'app'],
        'geliÅŸtirme': ['development', 'dev'],
        'iÅŸlem': ['process', 'procedure', 'operation'],
        'baÅŸvuru': ['application', 'request', 'form'],
        'izin': ['permission', 'leave', 'vacation'],
        'talep': ['request', 'demand'],
        'randevu': ['appointment', 'meeting'],
        'toplantÄ±': ['meeting', 'conference'],
        'iletiÅŸim': ['contact', 'communication', 'connection'],
        'ofis': ['office', 'bÃ¼ro', 'workplace'],
        'fabrika': ['factory', 'plant', 'tesis'],
        'kaÃ§ta': ['ne zaman', 'saat kaÃ§ta', 'when', 'what time'],
        'bilgi': ['information', 'info', 'detay', 'detail'],
        'hakkÄ±nda': ['about', 'konusunda', 'ile ilgili', 'regarding']
    }
    
    # Soru kalÄ±plarÄ± - TÃ¼rkÃ§e'ye Ã¶zel
    QUESTION_PATTERNS = [
        r'(.*?)\s+(nedir|ne|nelerdir|nasÄ±l|hangi|kim|nerede|ne zaman|kaÃ§|kaÃ§ta)',
        r'(.*?)\s+(hakkÄ±nda|ile ilgili|konusunda)\s+(bilgi|detay)',
        r'(.*?)\s+(yapÄ±lÄ±r|olur|edilir|alÄ±nÄ±r)',
        r'(.*?)\s+(var mÄ±|mevcut mu|bulunuyor mu)',
        r'(.*?)\s+(gerekli|lazÄ±m|ÅŸart)',
        r'(kaÃ§|kaÃ§ta|ne zaman)\s+(.*)',
        r'(nerede|hangi)\s+(.*)',
        r'(.*?)\s+(saatleri|zamanlarÄ±|hours)'
    ]
    
    @classmethod
    def normalize_text(cls, text: str) -> str:
        """Metni normalize et (kÃ¼Ã§Ã¼k harf, noktalama temizleme)"""
        if not text:
            return ""
        
        # Unicode normalize
        text = unicodedata.normalize('NFKD', text)
        
        # KÃ¼Ã§Ã¼k harfe Ã§evir
        text = text.lower()
        
        # Ekstra boÅŸluklarÄ± temizle
        text = ' '.join(text.split())
        
        # Noktalama iÅŸaretlerini temizle (bazÄ±larÄ± hariÃ§)
        text = re.sub(r'[^\w\sÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄžIÄ°Ã–ÅžÃœ]', ' ', text)
        
        return text.strip()
    
    @classmethod
    def remove_diacritics(cls, text: str) -> str:
        """TÃ¼rkÃ§e karakterleri ASCII karÅŸÄ±lÄ±klarÄ±na Ã§evir"""
        for turkish, ascii_char in cls.TURKISH_CHAR_MAP.items():
            text = text.replace(turkish, ascii_char)
        return text
    
    @classmethod
    def extract_question_core(cls, text: str) -> str:
        """Sorunun asÄ±l konusunu Ã§Ä±kar"""
        text = cls.normalize_text(text)
        
        # Soru kelimelerini kaldÄ±r
        question_words = ['ne', 'nedir', 'nelerdir', 'nasÄ±l', 'hangi', 'kim', 
                         'nerede', 'ne zaman', 'kaÃ§', 'kaÃ§ta', 'var mÄ±', 'mevcut mu']
        
        words = text.split()
        core_words = [w for w in words if w not in question_words]
        
        return ' '.join(core_words)
    
    @classmethod
    def expand_with_synonyms(cls, text: str) -> List[str]:
        """Metni eÅŸ anlamlÄ±larla geniÅŸlet"""
        words = cls.normalize_text(text).split()
        expanded_variations = [text]  # Orijinal metni de ekle
        
        for word in words:
            if word in cls.SYNONYMS:
                for synonym in cls.SYNONYMS[word]:
                    # Her eÅŸ anlamlÄ± iÃ§in yeni varyasyon oluÅŸtur
                    new_variation = text.replace(word, synonym)
                    expanded_variations.append(new_variation)
        
        return list(set(expanded_variations))  # TekrarlarÄ± kaldÄ±r

class FuzzyMatcher:
    """GeliÅŸmiÅŸ fuzzy matching algoritmalarÄ±"""
    
    @staticmethod
    def levenshtein_distance(s1: str, s2: str) -> int:
        """Levenshtein distance hesapla"""
        if len(s1) < len(s2):
            return FuzzyMatcher.levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    @staticmethod
    def similarity_ratio(s1: str, s2: str) -> float:
        """Ä°ki string arasÄ±ndaki benzerlik oranÄ± (0-1)"""
        if not s1 or not s2:
            return 0.0
        
        # SequenceMatcher kullan (Python built-in)
        matcher = SequenceMatcher(None, s1, s2)
        return matcher.ratio()
    
    @staticmethod
    def partial_ratio(s1: str, s2: str) -> float:
        """KÄ±smi eÅŸleÅŸme oranÄ±"""
        if not s1 or not s2:
            return 0.0
        
        shorter, longer = (s1, s2) if len(s1) <= len(s2) else (s2, s1)
        
        best_ratio = 0.0
        for i in range(len(longer) - len(shorter) + 1):
            substring = longer[i:i + len(shorter)]
            ratio = FuzzyMatcher.similarity_ratio(shorter, substring)
            best_ratio = max(best_ratio, ratio)
        
        return best_ratio
    
    @staticmethod
    def token_set_ratio(s1: str, s2: str) -> float:
        """Token set oranÄ± (kelime bazlÄ± karÅŸÄ±laÅŸtÄ±rma)"""
        if not s1 or not s2:
            return 0.0
        
        tokens1 = set(s1.lower().split())
        tokens2 = set(s2.lower().split())
        
        intersection = tokens1.intersection(tokens2)
        union = tokens1.union(tokens2)
        
        if not union:
            return 0.0
        
        return len(intersection) / len(union)

class EnhancedQuestionMatcher:
    """GeliÅŸmiÅŸ soru eÅŸleÅŸtirme sistemi"""
    
    def __init__(self, model_manager=None):
        self.normalizer = TurkishTextNormalizer()
        self.fuzzy_matcher = FuzzyMatcher()
        self.model_manager = model_manager
        
        # GeliÅŸmiÅŸ bilgi bankasÄ± - MEFAPEX iÃ§in Ã¶zelleÅŸtirilmiÅŸ
        self.knowledge_base = {
            "working_hours": {
                "keywords": [
                    "Ã§alÄ±ÅŸma saatleri", "calisma saatleri", "calÄ±ÅŸma saatleri", "iÅŸ saatleri", 
                    "mesai saatleri", "working hours", "work hours",
                    "Ã§alÄ±ÅŸma zamanÄ±", "iÅŸ zamanÄ±", "ofis saatleri", "fabrika saatleri",
                    "kaÃ§ta aÃ§Ä±k", "kaÃ§ta kapalÄ±", "ne zaman aÃ§Ä±k", "ne zaman kapalÄ±",
                    "saat kaÃ§", "Ã§alÄ±ÅŸma", "mesai", "working", "hours", "time",
                    "aÃ§Ä±lÄ±ÅŸ", "kapanÄ±ÅŸ", "opening", "closing", "saat", "zaman",
                    "Ã§alÄ±ÅŸma saati", "iÅŸ saati", "mesai saati"
                ],
                "patterns": [
                    r"Ã§alÄ±ÅŸ.*saat",
                    r"calis.*saat", 
                    r"calÄ±ÅŸ.*saat",
                    r"iÅŸ.*saat",
                    r"mesai.*saat",
                    r"saat.*ne.*zaman",
                    r"kaÃ§.*saat.*Ã§alÄ±ÅŸ",
                    r"ne.*zaman.*aÃ§Ä±k",
                    r"ne.*zaman.*kapalÄ±",
                    r"working.*hour",
                    r"work.*hour",
                    r"office.*hour"
                ],
                "title": "Ã‡alÄ±ÅŸma Saatleri ve Ä°letiÅŸim",
                "category": "working_hours"
            },
            "company_info": {
                "keywords": [
                    "mefapex", "ÅŸirket", "firma", "company", "hakkÄ±nda", "about",
                    "nedir", "bilgi", "information", "kim", "ne yapÄ±yor", "what",
                    "hizmetler", "services", "teknoloji", "biliÅŸim", "kimsiniz"
                ],
                "patterns": [
                    r"mefapex.*nedir",
                    r"mefapex.*hakkÄ±nda",
                    r"ÅŸirket.*bilgi",
                    r"firma.*nedir",
                    r"company.*info"
                ],
                "title": "MEFAPEX BiliÅŸim Teknolojileri HakkÄ±nda",
                "category": "company_info"
            },
            "technical_support": {
                "keywords": [
                    "teknik destek", "technical support", "destek", "support", "yardÄ±m", "help",
                    "problem", "sorun", "hata", "error", "arÄ±za", "bug",
                    "nasÄ±l alabilirim", "nasÄ±l ulaÅŸÄ±rÄ±m", "kim ile konuÅŸurum",
                    "yardÄ±ma ihtiyacÄ±m var", "destek lazÄ±m"
                ],
                "patterns": [
                    r"teknik.*destek",
                    r"destek.*nasÄ±l",
                    r"yardÄ±m.*alabilirim",
                    r"problem.*Ã§Ã¶zÃ¼m",
                    r"technical.*support"
                ],
                "title": "Teknik Destek",
                "category": "support_types"
            },
            "greetings": {
                "keywords": [
                    "merhaba", "merhabalar", "selam", "selamlar", "selamun aleykÃ¼m", "selamÃ¼naleykÃ¼m", 
                    "gÃ¼naydÄ±n", "iyi gÃ¼nler", "iyi akÅŸamlar", "iyi geceler", 
                    "nasÄ±lsÄ±n", "nasilsin", "nasÄ±l gidiyor", "naber", "nabersin", "naberin", "ne haber", 
                    "hoÅŸ geldin", "hoÅŸgeldin", "hello", "hi", "hey",
                    "good morning", "good afternoon", "good evening",
                    # Informal variations
                    "selammm", "selammmm", "merhabaaaa", "heyyyy", "hiii", "hiiii",
                    "slm", "mrb", "nbr", "nasÄ±lsÄ±nÄ±z", "nasilsiniz",
                    "nasÄ±l gidiyorsun", "nasÄ±l gidiyorsunuz", "ne yapÄ±yorsun", "ne yapÄ±yorsunuz",
                    "ne yapiyorsun", "ne yapiyorsunuz", "iÅŸler nasÄ±l", "isler nasil",
                    "keyifler nasÄ±l", "keyifler nasil", "everything ok", "whats up", "what's up", "wassup", "sup"
                ],
                "patterns": [
                    r"mer+haba+", r"selam+", r"gÃ¼naydÄ±n", r"hel+o+", r"hi+",
                    r"naber+\w*", r"nasÄ±l.*gid", r"ne.*yapÄ±yor", r"iÅŸler.*nasÄ±l",
                    r"whats+.*up", r"what.*up", r"was+up", r"sup+"
                ],
                "title": "Selamlama",
                "category": "greetings"
            },
            "thanks_goodbye": {
                "keywords": [
                    "teÅŸekkÃ¼r", "thanks", "saÄŸol", "gÃ¶rÃ¼ÅŸÃ¼rÃ¼z", "bye", "hoÅŸÃ§a kal",
                    "teÅŸekkÃ¼rler", "thank you", "saÄŸolun"
                ],
                "patterns": [
                    r"teÅŸekkÃ¼r",
                    r"thanks",
                    r"saÄŸol",
                    r"bye"
                ],
                "title": "TeÅŸekkÃ¼r ve Veda",
                "category": "thanks_goodbye"
            }
        }
        
        # Cache iÃ§in
        self._similarity_cache = {}
    
    @lru_cache(maxsize=1000)
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Cache'li benzerlik hesaplama"""
        # NormalleÅŸtir
        norm1 = self.normalizer.normalize_text(text1)
        norm2 = self.normalizer.normalize_text(text2)
        
        # FarklÄ± similarity metrikleri
        basic_ratio = self.fuzzy_matcher.similarity_ratio(norm1, norm2)
        partial_ratio = self.fuzzy_matcher.partial_ratio(norm1, norm2)
        token_ratio = self.fuzzy_matcher.token_set_ratio(norm1, norm2)
        
        # TÃ¼rkÃ§e karaktersiz versiyon da test et
        ascii1 = self.normalizer.remove_diacritics(norm1)
        ascii2 = self.normalizer.remove_diacritics(norm2)
        ascii_ratio = self.fuzzy_matcher.similarity_ratio(ascii1, ascii2)
        
        # En yÃ¼ksek skoru al
        max_score = max(basic_ratio, partial_ratio, token_ratio, ascii_ratio)
        
        return max_score
    
    def find_keyword_matches(self, question: str, category_data: Dict) -> Tuple[float, List[str]]:
        """Anahtar kelime eÅŸleÅŸtirmesi"""
        question_normalized = self.normalizer.normalize_text(question)
        question_words = set(question_normalized.split())
        
        matched_keywords = []
        total_score = 0.0
        
        # Direct keyword matching
        for keyword in category_data["keywords"]:
            keyword_normalized = self.normalizer.normalize_text(keyword)
            
            # Tam eÅŸleÅŸme
            if keyword_normalized in question_normalized:
                matched_keywords.append(keyword)
                total_score += 1.0
                continue
            
            # Fuzzy eÅŸleÅŸme
            similarity = self._calculate_similarity(question_normalized, keyword_normalized)
            if similarity > 0.65:  # %65 benzerlik eÅŸiÄŸi
                matched_keywords.append(keyword)
                total_score += similarity
                continue
            
            # Token-based eÅŸleÅŸme
            keyword_words = set(keyword_normalized.split())
            overlap = question_words.intersection(keyword_words)
            if overlap and len(overlap) >= len(keyword_words) * 0.5:  # %50 kelime Ã¶rtÃ¼ÅŸmesi
                matched_keywords.append(keyword)
                total_score += len(overlap) / len(keyword_words)
        
        # Pattern matching
        for pattern in category_data.get("patterns", []):
            if re.search(pattern, question_normalized):
                matched_keywords.append(f"pattern: {pattern}")
                total_score += 0.8
        
        # Normalize score
        final_score = min(total_score / len(category_data["keywords"]), 1.0) if category_data["keywords"] else 0.0
        
        return final_score, matched_keywords
    
    def semantic_similarity_search(self, question: str) -> List[QuestionMatch]:
        """Semantic similarity ile arama"""
        results = []
        
        # Model manager yoksa fuzzy matching'e geri dÃ¶n
        if not self.model_manager:
            return self._fallback_fuzzy_search(question)
        
        try:
            # Soru embedding'ini al
            question_embedding = self.model_manager.generate_embedding(question)
            if not question_embedding:
                return self._fallback_fuzzy_search(question)
            
            # Soruyu normalize et ve geniÅŸlet
            question_variations = self.normalizer.expand_with_synonyms(question)
            question_core = self.normalizer.extract_question_core(question)
            
            for category_key, category_data in self.knowledge_base.items():
                best_score = 0.0
                best_keywords = []
                best_semantic_score = 0.0
                
                # Keyword matching skoru
                keyword_score, keywords = self.find_keyword_matches(question, category_data)
                
                # Semantic similarity skoru
                try:
                    # Kategori iÃ§in enhanced text oluÅŸtur
                    category_text = f"{category_data['title']} {' '.join(category_data['keywords'][:10])}"
                    category_embedding = self.model_manager.generate_embedding(category_text)
                    
                    if category_embedding:
                        semantic_score = self._calculate_cosine_similarity(
                            question_embedding, category_embedding
                        )
                        best_semantic_score = semantic_score
                    
                except Exception as e:
                    logger.debug(f"Semantic similarity failed for {category_key}: {e}")
                    semantic_score = 0.0
                
                # Combined score (keyword + semantic)
                combined_score = (keyword_score * 0.6) + (best_semantic_score * 0.4)
                
                # Her soru varyasyonu iÃ§in de test et
                for variation in question_variations + [question_core]:
                    var_score, var_keywords = self.find_keyword_matches(variation, category_data)
                    if var_score > keyword_score:
                        keyword_score = var_score
                        keywords = var_keywords
                
                # Final score hesapla
                final_score = max(combined_score, keyword_score)
                
                # EÅŸik kontrolÃ¼
                if final_score > 0.25:  # Minimum %25 benzerlik
                    confidence = min(final_score * 1.3, 1.0)  # Boost confidence
                    
                    match = QuestionMatch(
                        original_question=question,
                        matched_content=category_data["title"],
                        similarity_score=final_score,
                        matching_keywords=keywords[:5],  # Ä°lk 5 anahtar kelime
                        match_type="semantic_enhanced",
                        confidence=confidence,
                        response="",  # Response content_manager'dan gelecek
                        category=category_data["category"]
                    )
                    results.append(match)
            
            # Skora gÃ¶re sÄ±rala
            results.sort(key=lambda x: x.confidence, reverse=True)
            return results
            
        except Exception as e:
            logger.error(f"Semantic search failed: {e}")
            return self._fallback_fuzzy_search(question)
    
    def _fallback_fuzzy_search(self, question: str) -> List[QuestionMatch]:
        """Fallback fuzzy search when semantic search fails"""
        results = []
        
        question_variations = self.normalizer.expand_with_synonyms(question)
        question_core = self.normalizer.extract_question_core(question)
        
        for category_key, category_data in self.knowledge_base.items():
            best_score = 0.0
            best_keywords = []
            
            # Her soru varyasyonu iÃ§in test et
            for variation in question_variations + [question_core]:
                score, keywords = self.find_keyword_matches(variation, category_data)
                if score > best_score:
                    best_score = score
                    best_keywords = keywords
            
            # EÅŸik kontrolÃ¼
            if best_score > 0.3:  # Minimum %30 benzerlik
                confidence = min(best_score * 1.1, 1.0)
                
                match = QuestionMatch(
                    original_question=question,
                    matched_content=category_data["title"],
                    similarity_score=best_score,
                    matching_keywords=best_keywords,
                    match_type="fuzzy_fallback",
                    confidence=confidence,
                    response="",
                    category=category_data["category"]
                )
                results.append(match)
        
        results.sort(key=lambda x: x.confidence, reverse=True)
        return results
    
    def _calculate_cosine_similarity(self, embedding1, embedding2) -> float:
        """Cosine similarity hesapla"""
        try:
            # NumPy array'e Ã§evir
            if isinstance(embedding1, list):
                embedding1 = np.array(embedding1)
            if isinstance(embedding2, list):
                embedding2 = np.array(embedding2)
            
            # Normalize embeddings
            norm1 = np.linalg.norm(embedding1)
            norm2 = np.linalg.norm(embedding2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            # Calculate cosine similarity
            similarity = np.dot(embedding1, embedding2) / (norm1 * norm2)
            return float(similarity)
            
        except Exception as e:
            logger.debug(f"Cosine similarity calculation error: {e}")
            return 0.0
    
    def _detect_intelligent_greeting(self, question: str) -> Optional[QuestionMatch]:
        """AkÄ±llÄ± selamlama tespiti - pattern matching ve repeated character detection"""
        
        normalized_text = self.normalizer.normalize_text(question.lower().strip())
        original_text = question.lower().strip()
        
        # Pattern-based greeting detection
        greeting_patterns = [
            # Temel selamlamalar ve varyasyonlarÄ±
            r"^(merhaba+|selam+|hi+|hey+|hello+)$",
            r"^(mrb|slm|nbr)$",  # KÄ±saltmalar
            
            # NasÄ±lsÄ±n variations
            r"^(naber|nabersin|naberin|ne haber)[\s\w]*$",
            r"^nasÄ±l[\s\w]*$",
            r"^ne[\s]+(yapÄ±yor|yapÄ±yorsun|yapÄ±yorsunuz)[\s\w]*$",
            r"^(iÅŸler|keyifler)[\s]+nasÄ±l[\s\w]*$",
            
            # English greetings
            r"^(whats+[\s]*up|what[\s]*up|sup+|wassup)[\s\w]*$",
            r"^(good[\s]+(morning|afternoon|evening|night))[\s\w]*$",
            
            # Repeated characters (selammm, heyyyy, etc)
            r"^(selam{2,}|merhaba{2,}|hi{2,}|hey{2,})[\s\w]*$",
            
            # GÃ¼nÃ¼n zamanÄ± selamlamalarÄ±
            r"^(gÃ¼naydÄ±n|iyi[\s]+(gÃ¼nler|akÅŸamlar|geceler))[\s\w]*$",
            
            # Mixed language patterns
            r"^(everything[\s]+ok|everything[\s]+fine)[\s\w]*$"
        ]
        
        # Pattern kontrolÃ¼
        for pattern in greeting_patterns:
            if re.match(pattern, normalized_text, re.IGNORECASE):
                logger.info(f"ðŸŽ¯ Intelligent greeting detected: '{question}' matched pattern: {pattern}")
                
                return QuestionMatch(
                    original_question=question,
                    category="greetings",
                    matched_content="Selamlama",
                    similarity_score=0.95,
                    matching_keywords=[pattern],
                    match_type="intelligent_greeting_pattern",
                    confidence=0.95,  # YÃ¼ksek confidence - pattern match
                    response="Greeting detected via pattern matching"
                )
        
        # Keyword-based greeting detection with repeated characters
        greeting_keywords = [
            "merhaba", "selam", "selamlar", "merhabalar", "gÃ¼naydÄ±n", "naber", "nabersin",
            "nasÄ±lsÄ±n", "nasilsin", "hi", "hello", "hey", "slm", "mrb", "nbr",
            "whats up", "what's up", "wassup", "sup", "ne yapÄ±yorsun", "iÅŸler nasÄ±l"
        ]
        
        # Repeated character detection (selammm -> selam)
        def clean_repeated_chars(text):
            """Tekrarlanan karakterleri temizle"""
            return re.sub(r'(.)\1{2,}', r'\1', text)
        
        cleaned_text = clean_repeated_chars(normalized_text)
        
        # Keyword match check
        for keyword in greeting_keywords:
            normalized_keyword = self.normalizer.normalize_text(keyword.lower())
            
            # Direct match
            if normalized_keyword in normalized_text or normalized_keyword in cleaned_text:
                logger.info(f"ðŸŽ¯ Intelligent greeting detected: '{question}' contains keyword: '{keyword}'")
                
                return QuestionMatch(
                    original_question=question,
                    category="greetings",
                    matched_content="Selamlama",
                    similarity_score=0.90,
                    matching_keywords=[keyword],
                    match_type="intelligent_greeting_keyword",
                    confidence=0.90,
                    response="Greeting detected via keyword matching"
                )
        
        # Short message heuristic - kÄ±sa mesajlar genelde greeting'dir
        words = normalized_text.split()
        if len(words) <= 3 and len(normalized_text) <= 15:
            # Greeting-like short messages
            short_greeting_patterns = [
                r"^[a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]{2,8}$",  # Tek kelime, makul uzunluk
                r"^[a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]{2,5}[\s]+[a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]{2,8}$",  # Ä°ki kelime
            ]
            
            for pattern in short_greeting_patterns:
                if re.match(pattern, normalized_text):
                    # Additional check - contains greeting-like characters
                    if any(char in normalized_text for char in ['selam', 'merh', 'naber', 'nasÄ±l', 'hey', 'hello']):
                        logger.info(f"ðŸŽ¯ Intelligent greeting detected: '{question}' short greeting heuristic")
                        
                        return QuestionMatch(
                            original_question=question,
                            category="greetings",
                            matched_content="Selamlama",
                            similarity_score=0.75,
                            matching_keywords=["short_heuristic"],
                            match_type="intelligent_greeting_heuristic",
                            confidence=0.75,
                            response="Greeting detected via heuristic analysis"
                        )
        
        return None
    
    def find_best_match(self, question: str, threshold: float = 0.35) -> Optional[QuestionMatch]:
        """En iyi eÅŸleÅŸmeyi bul"""
        
        # BoÅŸ soru kontrolÃ¼
        if not question or len(question.strip()) < 2:
            return None
        
        # Ã–nce intelligent greeting detection yap
        greeting_match = self._detect_intelligent_greeting(question)
        if greeting_match:
            return greeting_match
        
        # Semantic search
        matches = self.semantic_similarity_search(question)
        
        # En iyi eÅŸleÅŸmeyi seÃ§
        if matches and matches[0].confidence >= threshold:
            best_match = matches[0]
            
            logger.info(f"âœ… Enhanced Question matched: '{question}' -> '{best_match.matched_content}' "
                       f"(confidence: {best_match.confidence:.3f}, type: {best_match.match_type})")
            
            return best_match
        
        # EÅŸleÅŸme bulunamadÄ±
        if matches:
            logger.info(f"âŒ No strong match found for: '{question}' (best score: {matches[0].confidence:.3f})")
        else:
            logger.info(f"âŒ No match found for: '{question}'")
        
        return None

# Test fonksiyonu
def test_enhanced_question_matching():
    """GeliÅŸmiÅŸ soru eÅŸleÅŸtirmesini test et"""
    
    # Model manager'Ä± import et
    try:
        from model_manager import model_manager
        enhanced_matcher = EnhancedQuestionMatcher(model_manager)
    except ImportError:
        logger.warning("Model manager not available, using fallback")
        enhanced_matcher = EnhancedQuestionMatcher(None)
    
    test_questions = [
        # Ã‡alÄ±ÅŸma saatleri testleri
        ("Ã§alÄ±ÅŸma saatleri nelerdir?", "working_hours"),
        ("calisma saatleri nedir?", "working_hours"),  # TÃ¼rkÃ§e karakter olmadan
        ("calÄ±ÅŸma saatleri", "working_hours"),  # FarklÄ± yazÄ±m
        ("iÅŸ saatleri kaÃ§?", "working_hours"),
        ("ne zaman aÃ§Ä±k?", "working_hours"),
        ("mesai saatleri nedir?", "working_hours"),
        ("working hours nedir?", "working_hours"),  # Ä°ngilizce karÄ±ÅŸÄ±k
        ("fabrika kaÃ§ta aÃ§Ä±lÄ±yor?", "working_hours"),
        ("ofis saatleri", "working_hours"),
        ("saat kaÃ§ta aÃ§Ä±ksÄ±nÄ±z?", "working_hours"),
        
        # Åžirket bilgileri testleri
        ("mefapex nedir?", "company_info"),
        ("ÅŸirket hakkÄ±nda bilgi", "company_info"),
        ("firma ne yapÄ±yor?", "company_info"),
        ("mefapex kimdir?", "company_info"),
        
        # Teknik destek testleri
        ("teknik destek nasÄ±l alabilirim?", "technical_support"),
        ("yardÄ±ma ihtiyacÄ±m var", "technical_support"),
        ("problem Ã§Ã¶zÃ¼mÃ¼", "technical_support"),
        ("destek lazÄ±m", "technical_support"),
        
        # Selamlama testleri
        ("merhaba", "greetings"),
        ("selam nasÄ±lsÄ±n?", "greetings"),
        ("gÃ¼naydÄ±n", "greetings"),
        
        # TeÅŸekkÃ¼r testleri
        ("teÅŸekkÃ¼rler", "thanks_goodbye"),
        ("saÄŸol", "thanks_goodbye"),
        ("thanks", "thanks_goodbye"),
        
        # Ä°lgisiz sorular
        ("bugÃ¼n hava nasÄ±l?", None),  # EÅŸleÅŸmemeli
        ("futbol maÃ§Ä±", None)  # EÅŸleÅŸmemeli
    ]
    
    print("ðŸ§ª GELÄ°ÅžMÄ°Åž SORU EÅžLEÅžTÄ°RME TESTÄ°")
    print("=" * 80)
    
    correct_matches = 0
    total_tests = len(test_questions)
    
    for i, (question, expected_category) in enumerate(test_questions, 1):
        match = enhanced_matcher.find_best_match(question)
        
        # Kategorinin doÄŸru eÅŸleÅŸip eÅŸleÅŸmediÄŸini kontrol et
        if expected_category is None:
            # EÅŸleÅŸmemesi gereken sorular
            is_correct = match is None
            status = "âœ… PASS (No Match)" if is_correct else "âŒ FAIL (Unexpected Match)"
        else:
            # EÅŸleÅŸmesi gereken sorular
            is_correct = match is not None and match.category == expected_category
            status = "âœ… PASS" if is_correct else "âŒ FAIL"
        
        if is_correct:
            correct_matches += 1
        
        print(f"{i:2d}. {status} | {question}")
        print(f"    Expected: {expected_category}")
        if match:
            print(f"    Got: {match.category} (confidence: {match.confidence:.3f}, type: {match.match_type})")
            print(f"    Keywords: {match.matching_keywords[:3]}")
        else:
            print(f"    Got: No match")
        print()
    
    # SonuÃ§larÄ± gÃ¶ster
    accuracy = (correct_matches / total_tests) * 100
    print(f"ðŸ“Š TEST RESULTS:")
    print(f"    Correct: {correct_matches}/{total_tests}")
    print(f"    Accuracy: {accuracy:.1f}%")
    
    return accuracy > 85  # %85 Ã¼zeri baÅŸarÄ± bekliyoruz

if __name__ == "__main__":
    test_enhanced_question_matching()
